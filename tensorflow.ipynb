{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import warnings #ワーニング関連のモジュール？\n",
    "warnings.filterwarnings('ignore') #ワーニングが消える？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】スクラッチを振り返る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ノードと呼ばれる層の設定\n",
    "- 重みの初期化\n",
    "- 活性化関数の設定\n",
    "- ミニバッチを生成して局所的な学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】スクラッチとTensorFlowの対応を考える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "iris = load_iris()\n",
    "\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "X = pd.DataFrame(iris.data,columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"] )\n",
    "y = pd.DataFrame(iris.target,columns=[\"Species\"])\n",
    "X = X.loc[0:99,[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n",
    "y = y.loc[0:99,[\"Species\"]]\n",
    "\n",
    "y = np.array(y)\n",
    "X = np.array(X).astype(np.float32)\n",
    "#print(X)\n",
    "#print(y)\n",
    "#y = y.astype(np.float32)[:, np.newaxis]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# print(X)\n",
    "# print(y)\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# 正規化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 100\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "# 空配列定義\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "\n",
    "# trainのミニバッチイテレータ\n",
    "get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel(x): \n",
    "        # 重みの定義\n",
    "        w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]))\n",
    "        w2 = tf.Variable(tf.random.normal([n_hidden1, n_hidden2]))\n",
    "        w3 = tf.Variable(tf.random.normal([n_hidden2, n_classes]))\n",
    "        \n",
    "        # バイアスの定義\n",
    "        b1 = tf.Variable(tf.random.normal([n_hidden1]))\n",
    "        b2 = tf.Variable(tf.random.normal([n_hidden2]))\n",
    "        b3 = tf.Variable(tf.random.normal([n_classes]))\n",
    "        \n",
    "        # 計算グラフ構築（順伝播処理）\n",
    "        layer_1 = tf.add(tf.matmul(x,w1),b1)\n",
    "        layer_1 = tf.nn.relu(layer_1)\n",
    "        layer_2 = tf.add(tf.matmul(layer_1,w2),b2)\n",
    "        layer_2 = tf.nn.relu(layer_2)\n",
    "        layer_output = tf.matmul(layer_2,w3) + b3  # tf.addと+は等価である\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算グラフ受け取る\n",
    "logits = MyModel(X)\n",
    "# 損失定義\n",
    "loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n",
    "# 最適化手法の定義\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# 最適化手法で、定義した損失を最小化するルールを作成\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# ACC計算\n",
    "correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 変数を扱うためのおまじない\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-04 18:05:36.007370: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train_loss : 1.0716, val_loss : 0.8136, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 1, train_loss : 1.4281, val_loss : 1.0326, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 2, train_loss : 0.7319, val_loss : 0.6372, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 3, train_loss : 0.6801, val_loss : 0.6128, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 4, train_loss : 0.8448, val_loss : 0.6568, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 5, train_loss : 0.8982, val_loss : 0.6787, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 6, train_loss : 0.7318, val_loss : 0.5820, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 7, train_loss : 0.6930, val_loss : 0.5541, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 8, train_loss : 0.7339, val_loss : 0.5655, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 9, train_loss : 0.7382, val_loss : 0.5605, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 10, train_loss : 0.6860, val_loss : 0.5250, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 11, train_loss : 0.6484, val_loss : 0.4977, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 12, train_loss : 0.6367, val_loss : 0.4846, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 13, train_loss : 0.6264, val_loss : 0.4725, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 14, train_loss : 0.6034, val_loss : 0.4536, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 15, train_loss : 0.5757, val_loss : 0.4324, train_acc : 0.469, val_acc : 0.625\n",
      "Epoch 16, train_loss : 0.5520, val_loss : 0.4135, train_acc : 0.500, val_acc : 0.625\n",
      "Epoch 17, train_loss : 0.5322, val_loss : 0.3970, train_acc : 0.516, val_acc : 0.688\n",
      "Epoch 18, train_loss : 0.5122, val_loss : 0.3806, train_acc : 0.547, val_acc : 0.688\n",
      "Epoch 19, train_loss : 0.4905, val_loss : 0.3634, train_acc : 0.609, val_acc : 0.688\n",
      "Epoch 20, train_loss : 0.4682, val_loss : 0.3461, train_acc : 0.672, val_acc : 0.875\n",
      "Epoch 21, train_loss : 0.4464, val_loss : 0.3293, train_acc : 0.703, val_acc : 0.875\n",
      "Epoch 22, train_loss : 0.4254, val_loss : 0.3132, train_acc : 0.766, val_acc : 0.875\n",
      "Epoch 23, train_loss : 0.4050, val_loss : 0.2976, train_acc : 0.797, val_acc : 0.875\n",
      "Epoch 24, train_loss : 0.3848, val_loss : 0.2824, train_acc : 0.844, val_acc : 0.938\n",
      "Epoch 25, train_loss : 0.3650, val_loss : 0.2677, train_acc : 0.891, val_acc : 0.938\n",
      "Epoch 26, train_loss : 0.3458, val_loss : 0.2535, train_acc : 0.906, val_acc : 0.938\n",
      "Epoch 27, train_loss : 0.3274, val_loss : 0.2400, train_acc : 0.922, val_acc : 0.938\n",
      "Epoch 28, train_loss : 0.3099, val_loss : 0.2273, train_acc : 0.938, val_acc : 1.000\n",
      "Epoch 29, train_loss : 0.2933, val_loss : 0.2153, train_acc : 0.938, val_acc : 1.000\n",
      "Epoch 30, train_loss : 0.2777, val_loss : 0.2040, train_acc : 0.953, val_acc : 1.000\n",
      "Epoch 31, train_loss : 0.2630, val_loss : 0.1935, train_acc : 0.969, val_acc : 1.000\n",
      "Epoch 32, train_loss : 0.2493, val_loss : 0.1837, train_acc : 0.969, val_acc : 1.000\n",
      "Epoch 33, train_loss : 0.2365, val_loss : 0.1746, train_acc : 0.969, val_acc : 1.000\n",
      "Epoch 34, train_loss : 0.2247, val_loss : 0.1662, train_acc : 0.984, val_acc : 1.000\n",
      "Epoch 35, train_loss : 0.2138, val_loss : 0.1583, train_acc : 0.984, val_acc : 1.000\n",
      "Epoch 36, train_loss : 0.2036, val_loss : 0.1510, train_acc : 0.984, val_acc : 1.000\n",
      "Epoch 37, train_loss : 0.1941, val_loss : 0.1443, train_acc : 0.984, val_acc : 1.000\n",
      "Epoch 38, train_loss : 0.1854, val_loss : 0.1379, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 39, train_loss : 0.1772, val_loss : 0.1320, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 40, train_loss : 0.1696, val_loss : 0.1265, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 41, train_loss : 0.1625, val_loss : 0.1213, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 42, train_loss : 0.1559, val_loss : 0.1165, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 43, train_loss : 0.1496, val_loss : 0.1119, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 44, train_loss : 0.1438, val_loss : 0.1076, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 45, train_loss : 0.1383, val_loss : 0.1035, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 46, train_loss : 0.1332, val_loss : 0.0997, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 47, train_loss : 0.1283, val_loss : 0.0960, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 48, train_loss : 0.1237, val_loss : 0.0926, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 49, train_loss : 0.1194, val_loss : 0.0893, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 50, train_loss : 0.1153, val_loss : 0.0862, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 51, train_loss : 0.1114, val_loss : 0.0833, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 52, train_loss : 0.1077, val_loss : 0.0804, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 53, train_loss : 0.1041, val_loss : 0.0777, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 54, train_loss : 0.1008, val_loss : 0.0752, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 55, train_loss : 0.0976, val_loss : 0.0727, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 56, train_loss : 0.0946, val_loss : 0.0704, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 57, train_loss : 0.0917, val_loss : 0.0682, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 58, train_loss : 0.0889, val_loss : 0.0660, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 59, train_loss : 0.0863, val_loss : 0.0640, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 60, train_loss : 0.0837, val_loss : 0.0620, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 61, train_loss : 0.0813, val_loss : 0.0601, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 62, train_loss : 0.0790, val_loss : 0.0583, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 63, train_loss : 0.0768, val_loss : 0.0566, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 64, train_loss : 0.0746, val_loss : 0.0549, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 65, train_loss : 0.0726, val_loss : 0.0533, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 66, train_loss : 0.0706, val_loss : 0.0518, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 67, train_loss : 0.0687, val_loss : 0.0503, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 68, train_loss : 0.0669, val_loss : 0.0489, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 69, train_loss : 0.0652, val_loss : 0.0475, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 70, train_loss : 0.0635, val_loss : 0.0462, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 71, train_loss : 0.0619, val_loss : 0.0449, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 72, train_loss : 0.0603, val_loss : 0.0437, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 73, train_loss : 0.0588, val_loss : 0.0425, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 74, train_loss : 0.0574, val_loss : 0.0414, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 75, train_loss : 0.0560, val_loss : 0.0403, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 76, train_loss : 0.0546, val_loss : 0.0392, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 77, train_loss : 0.0533, val_loss : 0.0382, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 78, train_loss : 0.0521, val_loss : 0.0372, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 79, train_loss : 0.0508, val_loss : 0.0362, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 80, train_loss : 0.0497, val_loss : 0.0353, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 81, train_loss : 0.0485, val_loss : 0.0344, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 82, train_loss : 0.0474, val_loss : 0.0336, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 83, train_loss : 0.0464, val_loss : 0.0327, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 84, train_loss : 0.0453, val_loss : 0.0319, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 85, train_loss : 0.0443, val_loss : 0.0311, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 86, train_loss : 0.0434, val_loss : 0.0304, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 87, train_loss : 0.0424, val_loss : 0.0296, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 88, train_loss : 0.0415, val_loss : 0.0289, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 89, train_loss : 0.0406, val_loss : 0.0283, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 90, train_loss : 0.0398, val_loss : 0.0276, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 91, train_loss : 0.0389, val_loss : 0.0269, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 92, train_loss : 0.0381, val_loss : 0.0263, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 93, train_loss : 0.0373, val_loss : 0.0257, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 94, train_loss : 0.0366, val_loss : 0.0251, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 95, train_loss : 0.0359, val_loss : 0.0246, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 96, train_loss : 0.0351, val_loss : 0.0240, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 97, train_loss : 0.0344, val_loss : 0.0235, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 98, train_loss : 0.0338, val_loss : 0.0229, train_acc : 1.000, val_acc : 1.000\n",
      "Epoch 99, train_loss : 0.0331, val_loss : 0.0224, train_acc : 1.000, val_acc : 1.000\n",
      "test_acc : 1.000\n"
     ]
    }
   ],
   "source": [
    "# tensorflowのセッション開始\n",
    "with tf.Session() as sess:\n",
    "    # 初期化\n",
    "    sess.run(init)\n",
    "    # 学習回数分ループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # ミニバッチイテレータでループ\n",
    "        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # 「最適化手法で、定義した損失を最小化するルール」を実行\n",
    "            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n",
    "        # 記録\n",
    "        train_loss, train_acc = sess.run([loss_op, accuracy], feed_dict={X: X_train, Y: y_train})\n",
    "        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n",
    "        # 仮定出力\n",
    "        print(\"Epoch {}, train_loss : {:.4f}, val_loss : {:.4f}, train_acc : {:.3f}, val_acc : {:.3f}\".format(epoch, train_loss, val_loss, train_acc, val_acc))\n",
    "    \n",
    "    # 学習が終了したらテストデータで実行\n",
    "    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n",
    "    #prediction = sess.run(logits, feed_dict={X: X_test, Y: y_test})\n",
    "    #print(prediction)\n",
    "    print(\"test_acc : {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】3種類すべての目的変数を使用したIrisのモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(iris.data,columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"] )\n",
    "y = pd.DataFrame(iris.target,columns=[\"Species\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータ、評価データに分割\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=0)\n",
    "\n",
    "# onehotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train)\n",
    "# print(y_train)\n",
    "# print(y_train_one_hot)\n",
    "y_val_one_hot = enc.transform(y_val)\n",
    "# print(\"--------\")\n",
    "# print(y_val)\n",
    "# print(y_val_one_hot)\n",
    "y_test_one_hot = enc.transform(y_test)\n",
    "# print(\"--------\")\n",
    "# print(y_test)\n",
    "# print(y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflowで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数定義\n",
    "# 学習率\n",
    "leaning_rate = 0.01\n",
    "# バッチのサイズ\n",
    "batch_size = 10\n",
    "# 学習回数\n",
    "num_epochs = 100\n",
    "# １つ目のノード数\n",
    "n_hidden1 = 50\n",
    "# ２つ目のノード数\n",
    "n_hidden2 = 100\n",
    "# 出力するサイズ\n",
    "n_input = X_train.shape[1] #4\n",
    "\n",
    "#n_samples = X_train.shape[0]\n",
    "# 多値分類（３種類）のため\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空の配列を作る\n",
    "X = tf.placeholder(\"float\",[None,n_input])\n",
    "y = tf.placeholder(\"float\",[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 4)\n",
      "(None, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチイテレータ作成\n",
    "get_mini_batch_train = GetMiniBatch(X_train,y_train_one_hot,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"tensorflowを利用したニューラルネットワーク\n",
    "    --------\n",
    "    x : 入力配列\n",
    "    \"\"\"\n",
    "    # 重みの定義\n",
    "    # tf.random.normal = 正規分布から乱数を出力\n",
    "    # tf.variable = 変数に値を代入する\n",
    "    w1 = tf.Variable(tf.random.normal([n_input, n_hidden1]))\n",
    "    w2 = tf.Variable(tf.random.normal([n_hidden1,n_hidden2]))\n",
    "    w3 = tf.Variable(tf.random.normal([n_hidden2,n_classes]))\n",
    "    \n",
    "    # バイアスの定義\n",
    "    b1 = tf.Variable(tf.random.normal([n_hidden1]))\n",
    "    b2 = tf.Variable(tf.random.normal([n_hidden2]))\n",
    "    b3 = tf.Variable(tf.random.normal([n_classes]))\n",
    "    \n",
    "    # 計算グラフの構築\n",
    "    layer_1 = tf.add(tf.matmul(x,w1),b1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,w2),b2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.add(tf.matmul(layer_2,w3),b3)\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算グラフを受け取る\n",
    "logits = example_net(X)\n",
    "# 損失定義\n",
    "# ２値分類からの変更点\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = y, logits=logits))\n",
    "# 最適化手法の定義\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# 最適化手法で、定義した損失を最小化するルールを作成\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# ACC計算\n",
    "# ２値分類との違い\n",
    "# tf.signは要素ごとに数字の符号を返す\n",
    "# tf.equalは２つの引数の要素ごとの真偽値を返す\n",
    "correct_pred = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))\n",
    "# tf.reduce_mean = Tensorの要素の平均を計算\n",
    "# tf.cast( 変換したいもの , 変換後の型 )\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "# 変数の初期化という操作を行っており，計算グラフに変数が含まれている場合は，実行する必要があります．\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回目:train_loss:2.0572,val_loss:1.9764,train_acc:0.323,val_acc:0.333\n",
      "1回目:train_loss:1.6237,val_loss:1.6354,train_acc:0.365,val_acc:0.375\n",
      "2回目:train_loss:0.8274,val_loss:0.8389,train_acc:0.677,val_acc:0.625\n",
      "3回目:train_loss:0.8876,val_loss:0.8894,train_acc:0.688,val_acc:0.708\n",
      "4回目:train_loss:0.8173,val_loss:0.8307,train_acc:0.562,val_acc:0.583\n",
      "5回目:train_loss:0.8883,val_loss:0.9154,train_acc:0.604,val_acc:0.625\n",
      "6回目:train_loss:0.7846,val_loss:0.7938,train_acc:0.562,val_acc:0.583\n",
      "7回目:train_loss:0.7102,val_loss:0.7173,train_acc:0.854,val_acc:0.792\n",
      "8回目:train_loss:0.7125,val_loss:0.7266,train_acc:0.604,val_acc:0.625\n",
      "9回目:train_loss:0.6795,val_loss:0.6868,train_acc:0.750,val_acc:0.708\n",
      "10回目:train_loss:0.6561,val_loss:0.6651,train_acc:0.802,val_acc:0.792\n",
      "11回目:train_loss:0.6319,val_loss:0.6406,train_acc:0.927,val_acc:0.958\n",
      "12回目:train_loss:0.6114,val_loss:0.6196,train_acc:0.927,val_acc:0.958\n",
      "13回目:train_loss:0.5926,val_loss:0.6006,train_acc:0.927,val_acc:0.958\n",
      "14回目:train_loss:0.5722,val_loss:0.5801,train_acc:0.938,val_acc:0.958\n",
      "15回目:train_loss:0.5540,val_loss:0.5623,train_acc:0.938,val_acc:0.958\n",
      "16回目:train_loss:0.5365,val_loss:0.5448,train_acc:0.938,val_acc:0.917\n",
      "17回目:train_loss:0.5202,val_loss:0.5288,train_acc:0.938,val_acc:0.917\n",
      "18回目:train_loss:0.5044,val_loss:0.5133,train_acc:0.938,val_acc:0.917\n",
      "19回目:train_loss:0.4894,val_loss:0.4986,train_acc:0.938,val_acc:0.917\n",
      "20回目:train_loss:0.4752,val_loss:0.4849,train_acc:0.938,val_acc:0.917\n",
      "21回目:train_loss:0.4616,val_loss:0.4717,train_acc:0.948,val_acc:0.958\n",
      "22回目:train_loss:0.4489,val_loss:0.4595,train_acc:0.948,val_acc:0.958\n",
      "23回目:train_loss:0.4366,val_loss:0.4476,train_acc:0.948,val_acc:0.958\n",
      "24回目:train_loss:0.4248,val_loss:0.4364,train_acc:0.948,val_acc:0.958\n",
      "25回目:train_loss:0.4136,val_loss:0.4259,train_acc:0.948,val_acc:0.958\n",
      "26回目:train_loss:0.4029,val_loss:0.4157,train_acc:0.948,val_acc:0.958\n",
      "27回目:train_loss:0.3924,val_loss:0.4060,train_acc:0.948,val_acc:0.958\n",
      "28回目:train_loss:0.3825,val_loss:0.3968,train_acc:0.948,val_acc:0.958\n",
      "29回目:train_loss:0.3729,val_loss:0.3879,train_acc:0.948,val_acc:0.958\n",
      "30回目:train_loss:0.3636,val_loss:0.3794,train_acc:0.948,val_acc:0.958\n",
      "31回目:train_loss:0.3545,val_loss:0.3713,train_acc:0.948,val_acc:0.958\n",
      "32回目:train_loss:0.3457,val_loss:0.3635,train_acc:0.948,val_acc:0.958\n",
      "33回目:train_loss:0.3372,val_loss:0.3560,train_acc:0.948,val_acc:0.958\n",
      "34回目:train_loss:0.3288,val_loss:0.3488,train_acc:0.948,val_acc:0.958\n",
      "35回目:train_loss:0.3208,val_loss:0.3420,train_acc:0.948,val_acc:0.958\n",
      "36回目:train_loss:0.3130,val_loss:0.3355,train_acc:0.948,val_acc:0.958\n",
      "37回目:train_loss:0.3054,val_loss:0.3293,train_acc:0.948,val_acc:0.958\n",
      "38回目:train_loss:0.2982,val_loss:0.3235,train_acc:0.948,val_acc:0.958\n",
      "39回目:train_loss:0.2912,val_loss:0.3181,train_acc:0.948,val_acc:0.958\n",
      "40回目:train_loss:0.2846,val_loss:0.3131,train_acc:0.958,val_acc:0.917\n",
      "41回目:train_loss:0.2783,val_loss:0.3085,train_acc:0.958,val_acc:0.917\n",
      "42回目:train_loss:0.2723,val_loss:0.3043,train_acc:0.958,val_acc:0.917\n",
      "43回目:train_loss:0.2667,val_loss:0.3004,train_acc:0.958,val_acc:0.917\n",
      "44回目:train_loss:0.2615,val_loss:0.2970,train_acc:0.958,val_acc:0.917\n",
      "45回目:train_loss:0.2567,val_loss:0.2941,train_acc:0.958,val_acc:0.917\n",
      "46回目:train_loss:0.2522,val_loss:0.2915,train_acc:0.958,val_acc:0.917\n",
      "47回目:train_loss:0.2482,val_loss:0.2894,train_acc:0.958,val_acc:0.917\n",
      "48回目:train_loss:0.2447,val_loss:0.2877,train_acc:0.958,val_acc:0.917\n",
      "49回目:train_loss:0.2415,val_loss:0.2865,train_acc:0.958,val_acc:0.917\n",
      "50回目:train_loss:0.2389,val_loss:0.2858,train_acc:0.958,val_acc:0.875\n",
      "51回目:train_loss:0.2368,val_loss:0.2855,train_acc:0.958,val_acc:0.875\n",
      "52回目:train_loss:0.2352,val_loss:0.2857,train_acc:0.958,val_acc:0.875\n",
      "53回目:train_loss:0.2341,val_loss:0.2864,train_acc:0.948,val_acc:0.875\n",
      "54回目:train_loss:0.2337,val_loss:0.2876,train_acc:0.938,val_acc:0.875\n",
      "55回目:train_loss:0.2339,val_loss:0.2895,train_acc:0.948,val_acc:0.875\n",
      "56回目:train_loss:0.2347,val_loss:0.2917,train_acc:0.948,val_acc:0.875\n",
      "57回目:train_loss:0.2360,val_loss:0.2945,train_acc:0.948,val_acc:0.875\n",
      "58回目:train_loss:0.2379,val_loss:0.2976,train_acc:0.948,val_acc:0.875\n",
      "59回目:train_loss:0.2404,val_loss:0.3012,train_acc:0.948,val_acc:0.875\n",
      "60回目:train_loss:0.2433,val_loss:0.3051,train_acc:0.948,val_acc:0.875\n",
      "61回目:train_loss:0.2466,val_loss:0.3093,train_acc:0.948,val_acc:0.875\n",
      "62回目:train_loss:0.2502,val_loss:0.3137,train_acc:0.948,val_acc:0.875\n",
      "63回目:train_loss:0.2539,val_loss:0.3180,train_acc:0.948,val_acc:0.875\n",
      "64回目:train_loss:0.2577,val_loss:0.3223,train_acc:0.958,val_acc:0.875\n",
      "65回目:train_loss:0.2612,val_loss:0.3263,train_acc:0.958,val_acc:0.875\n",
      "66回目:train_loss:0.2643,val_loss:0.3297,train_acc:0.948,val_acc:0.875\n",
      "67回目:train_loss:0.2667,val_loss:0.3324,train_acc:0.948,val_acc:0.875\n",
      "68回目:train_loss:0.2682,val_loss:0.3341,train_acc:0.948,val_acc:0.875\n",
      "69回目:train_loss:0.2684,val_loss:0.3346,train_acc:0.938,val_acc:0.875\n",
      "70回目:train_loss:0.2674,val_loss:0.3338,train_acc:0.938,val_acc:0.875\n",
      "71回目:train_loss:0.2652,val_loss:0.3317,train_acc:0.938,val_acc:0.875\n",
      "72回目:train_loss:0.2620,val_loss:0.3286,train_acc:0.938,val_acc:0.875\n",
      "73回目:train_loss:0.2581,val_loss:0.3250,train_acc:0.938,val_acc:0.875\n",
      "74回目:train_loss:0.2540,val_loss:0.3211,train_acc:0.948,val_acc:0.875\n",
      "75回目:train_loss:0.2499,val_loss:0.3173,train_acc:0.948,val_acc:0.875\n",
      "76回目:train_loss:0.2460,val_loss:0.3137,train_acc:0.948,val_acc:0.875\n",
      "77回目:train_loss:0.2421,val_loss:0.3101,train_acc:0.948,val_acc:0.875\n",
      "78回目:train_loss:0.2384,val_loss:0.3067,train_acc:0.948,val_acc:0.875\n",
      "79回目:train_loss:0.2348,val_loss:0.3034,train_acc:0.948,val_acc:0.875\n",
      "80回目:train_loss:0.2311,val_loss:0.3000,train_acc:0.948,val_acc:0.875\n",
      "81回目:train_loss:0.2279,val_loss:0.2970,train_acc:0.948,val_acc:0.875\n",
      "82回目:train_loss:0.2250,val_loss:0.2943,train_acc:0.948,val_acc:0.917\n",
      "83回目:train_loss:0.2222,val_loss:0.2917,train_acc:0.948,val_acc:0.917\n",
      "84回目:train_loss:0.2194,val_loss:0.2891,train_acc:0.948,val_acc:0.917\n",
      "85回目:train_loss:0.2159,val_loss:0.2858,train_acc:0.948,val_acc:0.917\n",
      "86回目:train_loss:0.2137,val_loss:0.2838,train_acc:0.948,val_acc:0.917\n",
      "87回目:train_loss:0.2117,val_loss:0.2819,train_acc:0.948,val_acc:0.917\n",
      "88回目:train_loss:0.2094,val_loss:0.2798,train_acc:0.948,val_acc:0.917\n",
      "89回目:train_loss:0.2080,val_loss:0.2783,train_acc:0.948,val_acc:0.917\n",
      "90回目:train_loss:0.2062,val_loss:0.2765,train_acc:0.948,val_acc:0.917\n",
      "91回目:train_loss:0.2057,val_loss:0.2759,train_acc:0.948,val_acc:0.917\n",
      "92回目:train_loss:0.2069,val_loss:0.2767,train_acc:0.938,val_acc:0.917\n",
      "93回目:train_loss:0.2083,val_loss:0.2777,train_acc:0.938,val_acc:0.917\n",
      "94回目:train_loss:0.2106,val_loss:0.2794,train_acc:0.938,val_acc:0.917\n",
      "95回目:train_loss:0.2109,val_loss:0.2792,train_acc:0.938,val_acc:0.917\n",
      "96回目:train_loss:0.1978,val_loss:0.2664,train_acc:0.938,val_acc:0.917\n",
      "97回目:train_loss:0.1488,val_loss:0.2229,train_acc:0.958,val_acc:0.917\n",
      "98回目:train_loss:0.1069,val_loss:0.1836,train_acc:0.958,val_acc:0.917\n",
      "99回目:train_loss:0.1022,val_loss:0.1737,train_acc:0.958,val_acc:0.917\n",
      "test_acc:1.000\n"
     ]
    }
   ],
   "source": [
    "# tensorflowのSession開始\n",
    "with tf.Session() as sess:\n",
    "    # 初期化\n",
    "    # 必須\n",
    "    sess.run(init)\n",
    "    # 学習回数分ループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # ミニバッチイテレータでループ\n",
    "        for i,(mini_batch_x,mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # ここで「最適化手法で、定義した損失を最小化するルール」を実行\n",
    "            sess.run(train_op,feed_dict={X: mini_batch_x, y: mini_batch_y})\n",
    "        # 記録\n",
    "        train_loss,train_acc = sess.run([loss_op,accuracy],feed_dict={X: X_train,y: y_train_one_hot})\n",
    "        val_loss,val_acc = sess.run([loss_op,accuracy],feed_dict={X: X_val,y: y_val_one_hot})\n",
    "        # 仮定出力\n",
    "        print(\"{}回目:train_loss:{:.4f},val_loss:{:.4f},train_acc:{:.3f},val_acc:{:.3f}\".format(epoch,train_loss,val_loss,train_acc,val_acc))\n",
    "        \n",
    "    # 学習が終了したらテストデータで実行\n",
    "    test_acc = sess.run(accuracy,feed_dict={X:X_test, y:y_test_one_hot})\n",
    "    print(\"test_acc:{:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】House Pricesのモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460,)\n",
      "(1460, 2)\n",
      "(1460, 1)\n",
      "[[12.24769432]\n",
      " [12.10901093]\n",
      " [12.31716669]\n",
      " ...\n",
      " [12.49312952]\n",
      " [11.86446223]\n",
      " [11.90158345]]\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"train.csv\" # ファイル名（パス）を指定する\n",
    "\n",
    "'''学習用データの読み込み'''\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:,[\"GrLivArea\",\"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "print(y.shape)\n",
    "print(X.shape)\n",
    "# newaxis = 次元を増やす\n",
    "y = y.astype(np.int)[:,np.newaxis]\n",
    "# np.logで対数変換\n",
    "y = np.log(y)\n",
    "print(y.shape)\n",
    "print(y)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数定義\n",
    "learning_rate = 0.001\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_classes = 1\n",
    "\n",
    "# 空の配列\n",
    "X = tf.placeholder(\"float\",[None,n_input])\n",
    "y = tf.placeholder(\"float\",[None,n_classes])\n",
    "\n",
    "# ミニバッチイテレータ生成\n",
    "get_mini_batch_train = GetMiniBatch(X_train,y_train,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    tensorflowを利用したニューラルネットワーク\n",
    "    --------\n",
    "    X : 入力配列\n",
    "    \"\"\"\n",
    "    # 重みの定義\n",
    "    w1 = tf.Variable(tf.random_normal([n_input,n_hidden1]))\n",
    "    w2 = tf.Variable(tf.random_normal([n_hidden1,n_hidden2]))\n",
    "    w3 = tf.Variable(tf.random_normal([n_hidden2,n_classes]))\n",
    "    \n",
    "    # バイアスの定義\n",
    "    b1 = tf.Variable(tf.random_normal([n_hidden1]))\n",
    "    b2 = tf.Variable(tf.random_normal([n_hidden2]))\n",
    "    b3 = tf.Variable(tf.random_normal([n_classes]))\n",
    "    \n",
    "    # 計算グラフ構築\n",
    "    layer_1 = tf.add(tf.matmul(x,w1),b1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,w2),b2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.add(tf.matmul(layer_2,w3),b3)\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算グラフを受け取る\n",
    "logits = example_net(X)\n",
    "# 損失定義\n",
    "loss_op = tf.losses.mean_squared_error(labels=y,predictions=logits)\n",
    "# 最適化手法の定義\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate =learning_rate)\n",
    "# 最適化手法で、定義した損失を最小化するルールを作成\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# 変数の初期化という操作を行っており，計算グラフに変数が含まれている場合は，実行する必要があります．\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回目/loss:1793203.6250,val_loss:1856748.7500\n",
      "1回目/loss:452947.8750,val_loss:455438.4688\n",
      "2回目/loss:246724.8594,val_loss:214348.0000\n",
      "3回目/loss:161734.5625,val_loss:130783.8203\n",
      "4回目/loss:109299.4766,val_loss:83131.7188\n",
      "5回目/loss:78729.7734,val_loss:56498.0938\n",
      "6回目/loss:62072.3828,val_loss:43247.2734\n",
      "7回目/loss:52154.7227,val_loss:36275.9492\n",
      "8回目/loss:45263.7422,val_loss:31973.5957\n",
      "9回目/loss:39835.3242,val_loss:28739.6074\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_mse : 424884.594\n"
     ]
    }
   ],
   "source": [
    "# tensorflowのSession開始\n",
    "with tf.Session() as sess:\n",
    "    # 初期化\n",
    "    sess.run(init)\n",
    "    # 損失記録用\n",
    "    loss_list = []\n",
    "    val_loss_list = []\n",
    "    # 学習回数ループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # ミニバッチイテレータでループ\n",
    "        for i,(mini_batch_x,mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # 「最適化手法で、定義した損失を最小化するルール」を実行\n",
    "            sess.run(train_op,feed_dict={X: mini_batch_x, y: mini_batch_y})\n",
    "        # 損失計算\n",
    "        loss = sess.run(loss_op,feed_dict = {X:X_train,y: y_train})\n",
    "        val_loss = sess.run(loss_op,feed_dict = {X: X_val, y: y_val})\n",
    "        # 格納\n",
    "        loss_list.append(loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        print(\"{}回目/loss:{:.4f},val_loss:{:.4f}\".format(epoch,loss,val_loss))\n",
    "    \n",
    "    # 学習過程可視化\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.plot(loss_list, label='loss')\n",
    "    plt.plot(val_loss_list, label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#     # テストデータに適用    \n",
    "    test_loss = sess.run(loss_op, feed_dict={X: X_test, y: y_test})\n",
    "    print(\"test_mse : {:.3f}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】MNISTのモデルを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n",
    "\n",
    "\n",
    "3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n",
    "\n",
    "\n",
    "スクラッチで実装したモデルの再現を目指してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データ→行データに\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# 変形\n",
    "y_train = y_train.astype(np.int)[:, np.newaxis]\n",
    "y_test = y_test.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# one-hotベクトル化\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:])\n",
    "y_test_one_hot = enc.fit_transform(y_test[:])\n",
    "\n",
    "# 分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowで学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変数の定義\n",
    "learning_rate = 0.003\n",
    "batch_size = 1\n",
    "num_epochs = 20\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "# 2値分類との違い\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 空の配列を生成\n",
    "X = tf.placeholder(\"float\",[None,n_input])\n",
    "y = tf.placeholder(\"float\",[None,n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチイテレータ生成\n",
    "get_mini_batch_train = GetMiniBatch(X_train[:1000],y_train[:1000],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_net(x):\n",
    "    \"\"\"\n",
    "    Tensorflowを利用したニューラルネットワーク\n",
    "    --------\n",
    "    x : 入力配列\n",
    "    \"\"\"\n",
    "    # 重みの定義\n",
    "    w1 = tf.Variable(tf.random_normal([n_input,n_hidden1]))\n",
    "    w2 = tf.Variable(tf.random_normal([n_hidden1,n_hidden2]))\n",
    "    w3 = tf.Variable(tf.random_normal([n_hidden2,n_classes]))\n",
    "    \n",
    "    # バイアスの定義\n",
    "    b1 = tf.Variable(tf.random_normal([n_hidden1]))\n",
    "    b2 = tf.Variable(tf.random_normal([n_hidden2]))\n",
    "    b3 = tf.Variable(tf.random_normal([n_classes]))\n",
    "    \n",
    "    # 計算グラフ構築\n",
    "    layer_1 = tf.add(tf.matmul(x,w1),b1)\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,w2),b2)\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    layer_output = tf.add(tf.matmul(layer_2,w3),b3)\n",
    "    \n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算グラフを受け取る\n",
    "logits = example_net(X)\n",
    "# 損失定義\n",
    "# 2値分類との違い\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=logits))\n",
    "# 最適化手法の定義\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# 最適化手法で、定義した損失を最小化するルールを作成\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "# ACC計算\n",
    "# 2値分類との違い\n",
    "correct_pred = tf.equal(tf.argmax(y,1),tf.argmax(logits,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))\n",
    "\n",
    "# 変数の初期化という操作を行っており，計算グラフに変数が含まれている場合は，実行する必要があります．\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回目/train_loss:32.4214,val_loss:32.8632,train_acc:0.610,val_acc:0.612\n",
      "1回目/train_loss:21.7742,val_loss:22.0962,train_acc:0.687,val_acc:0.687\n",
      "2回目/train_loss:20.8667,val_loss:20.8545,train_acc:0.697,val_acc:0.696\n",
      "3回目/train_loss:19.5480,val_loss:19.2272,train_acc:0.724,val_acc:0.727\n",
      "4回目/train_loss:17.5583,val_loss:17.3489,train_acc:0.749,val_acc:0.748\n",
      "5回目/train_loss:17.8939,val_loss:17.8153,train_acc:0.757,val_acc:0.757\n",
      "6回目/train_loss:18.7267,val_loss:17.8834,train_acc:0.763,val_acc:0.761\n",
      "7回目/train_loss:18.2683,val_loss:17.7615,train_acc:0.781,val_acc:0.778\n",
      "8回目/train_loss:17.9142,val_loss:17.4564,train_acc:0.793,val_acc:0.789\n",
      "9回目/train_loss:18.8882,val_loss:18.7072,train_acc:0.782,val_acc:0.778\n",
      "10回目/train_loss:20.0908,val_loss:19.8965,train_acc:0.785,val_acc:0.786\n",
      "11回目/train_loss:17.0971,val_loss:17.0514,train_acc:0.817,val_acc:0.814\n",
      "12回目/train_loss:18.9296,val_loss:18.8236,train_acc:0.803,val_acc:0.793\n",
      "13回目/train_loss:20.0733,val_loss:20.4545,train_acc:0.807,val_acc:0.802\n",
      "14回目/train_loss:18.1359,val_loss:18.4771,train_acc:0.828,val_acc:0.826\n",
      "15回目/train_loss:21.7943,val_loss:22.0672,train_acc:0.824,val_acc:0.820\n",
      "16回目/train_loss:25.6059,val_loss:26.3458,train_acc:0.806,val_acc:0.803\n",
      "17回目/train_loss:20.8925,val_loss:20.9483,train_acc:0.820,val_acc:0.812\n",
      "18回目/train_loss:21.8361,val_loss:21.0328,train_acc:0.816,val_acc:0.813\n",
      "19回目/train_loss:20.4120,val_loss:20.4853,train_acc:0.827,val_acc:0.821\n",
      "--------\n",
      "test_acc:0.831\n"
     ]
    }
   ],
   "source": [
    "# tensorflowのsession開始\n",
    "with tf.Session() as sess:\n",
    "    # 初期化\n",
    "    sess.run(init)\n",
    "    # 学習分だけループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # ミニバッチイテレータでループ\n",
    "        for i,(mini_batch_x,mini_batch_y) in enumerate(get_mini_batch_train):\n",
    "            # 「最適化手法で、定義した損失を最小化するルール」を実行\n",
    "            sess.run(train_op,feed_dict={X:mini_batch_x,y:mini_batch_y})\n",
    "        # 記録\n",
    "        train_loss,train_acc = sess.run([loss_op,accuracy],feed_dict={X:X_train,y:y_train})\n",
    "        val_loss,val_acc = sess.run([loss_op,accuracy],feed_dict={X:X_val,y:y_val})\n",
    "        # 仮定出力\n",
    "        print(\"{}回目/train_loss:{:.4f},val_loss:{:.4f},train_acc:{:.3f},val_acc:{:.3f}\".format(epoch,train_loss,val_loss,train_acc,val_acc))\n",
    "        \n",
    "    # 学習が終了したらテストデータで実行\n",
    "    test_acc = sess.run(accuracy,feed_dict={X:X_test,y:y_test_one_hot})\n",
    "    print(\"--------\")\n",
    "    print(\"test_acc:{:.3f}\".format(test_acc))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
